# Start from the official Airflow image
FROM apache/airflow:2.8.2

# Switch to root user to install packages
USER root
# Install Java, which is required by the Spark provider
RUN apt-get update && apt-get install -y default-jre
# Switch back to the airflow user
USER airflow

# Install PySpark and Apache Spark provider for Airflow
RUN pip install --no-cache-dir pyspark==3.5.0 apache-airflow-providers-apache-spark